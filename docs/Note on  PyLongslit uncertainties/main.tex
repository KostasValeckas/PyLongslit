\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{url}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[style=numeric,minbibnames=3,natbib=true]{biblatex}
\addbibresource{bib.bib}

\title{Note on  PyLongslit uncertainties}
\author{Kostas Valeckas, NBI, University of Copenhagen}
\date{February 2025}

\begin{document}

\maketitle


This is a note describing uncertainties in the PyLongslit\footnote{\url{https://github.com/KostasValeckas/PyLongslit/tree/develop}} software. For now for internal use only.

\tableofcontents


\section{General remarks}

The error propagation in a pipeline like PyLongslit can get extremely complicated. This is due to the many pipeline steps both include modelling and direct calculations, sometimes with the errors being somewhat correlated. For the PyLongslit software, a simple, yet consistent approach is taken to give an error estimate of the pipeline products. We provide a transparent and complete description on how the errors are calculated, and we especially disclose where simplifications/approximations are made in error estimation.

\subsection{Errors on fitted models}

The pipeline relies heavily on fitting mathematical models to data. The models are adjustable from the user-site, meaning that a constant number of fit parameters can not be assumed. Performing analytical error estimation for these variable models, while possible, would be extremely complicated and would increase the code complexity marginally - and therefore also make the code more vulnerable to errors. Therefore, \textbf{a heavily simplified, but robust} error estimation is used for the values produced by a fitted model. For a fitted model $f_{\text{model}}$, the error on the value estimated by the model is:

\begin{equation}\label{model_error}
    \sigma_{f_{\text{model}}} = \text{RMS}({f_{model}}(\textbf{x}) - y(\textbf{x})) \ \ ,
\end{equation}

\noindent where RMS stands for the \textit{root mean square} ($\sqrt{\frac{x_{1}^2 + x_{2}^2 + ... + x_{N}^2}{N}}$), and the difference between $f_{\text{model}}(\textbf{x})$ and $y(\textbf{x})$ represents the residuals, where the input vector $\textbf{x}$ are the independent and $y$ are the dependent data-points used for model fitting. The RMS residual metric, in experience, gives a sufficient estimate of the order of magnitude of the error, but lacks nuance as it is independent of what input vector $\textbf{x}$ is passed to the model. Therefore, the software is engineered to produce \textbf{quality assessment plots} for every fitted model, and the user should inspect these carefully to estimate the overall quality and systematic errors of the fitted model. 

\subsection{Errors on direct computations}

For a value $f(\textbf{x})$, the error is estimated by the \textbf{law of combination of errors} \cite[eq. 4.14]{barlow1995statistics}: 

\begin{equation}\label{combination}
    \sigma_{f(\textbf{x})} = \sqrt{\left(\frac{\partial f(\textbf{x})}{\partial x_{1}}\right)^2 \sigma_{x_1}^2 + \left(\frac{\partial f(\textbf{x})}{\partial x_{2}}\right)^2 \sigma_{x_2}^2 + ... + \left(\frac{\partial f(\textbf{x})}{\partial x_{N}}\right)^2 \sigma_{x_N}^2} \ \ ,
\end{equation}

\noindent where the uncertainties $\sigma_{x_{i}}$ on the input vector $\textbf{x} = (x_{1}, x_{2}, ..., x_{N} )$, are assumed to be uncorrelated.

\section{Calibration errors}

\subsection{Master bias}\label{master bias}

The master bias $B_{master}$ is constructed by taking a median of every $(x,y)$ pixel value from $N$ stacked (potentially overscan subtracted\footnote{The user can choose whether or not to subtract overscan - as this option might not be relevant for some instruments.}) bias frames $B$:

\begin{equation}\label{bias_eq}
    B_{\text{master}}(x,y) = \text{Median}(\{B_{i}(x,y), i = 1 ... N\}) \ \ .
\end{equation}

\noindent The error on the median can be estimated in two ways (choice is made by the user). The first, most straightforward way is to approximate the error by using an empirical formula \cite[ch. 9.2]{Wackerly2007-dp},
\begin{equation}
    \sigma_{B_{\text{master}}(x,y)} = \frac{1.2533 \ \sigma_{std(x,y)}}{\sqrt{N}} \ \ ,
\end{equation}

\noindent where $\sigma_{std(x,y)}$ is the standard deviation of the pixel $(x,y)$ in the bias stack. The issue with using this formula is that $N$ must be large for it to guarantee correctness. If the number of raw bias frames is small ($N < 30$), the software will throw a warning about the error estimation on the master bias possibly not being correct. The user can instead choose to use a bootstrapping algorithm to estimate the errors. The algorithm runs as follows:

\begin{enumerate}
    \item From the existing collection of bias frames, pick the same amount of frames by randomly picking one frame at a time, allowing the same frame to be chosen several times (random resampling).
    \item Calculate the median of the sample. \\ 
    -------------- after this is repeated for 1000 iterations --------
    \item Calculate the standard deviation of all the resampled medians.
\end{enumerate}

\noindent This should provide a somewhat correct error estimation on the median even for small $N$ of bias frames. The trade-off is that since the detector-array sizes are easily in the order of $10^3 \cdot 10^3$, even 1000 re-samples takes several minutes to perform. The user can decide whether this is necessary for the given science case and instrument.

\subsubsection{Ignoring errors from overscan subtraction}\label{ignore_overscan}

If the user decides to use overscan subtraction, this also introduces some additional errors in the bias frames. However, these errors are not used in the above described procedure. The reason for this is that for regular median estimation, errors do not change the outcome. A weighted median could be used, but this is deemed unnecessary. This would introduce additional complexity and computations - with very likely no noticeable impact on the results - as the regular (non-weighted) median is extremely robust to outliers as it is \cite{barlow1995statistics}.

\subsection{Wavelength calibration}

The wavelength calibration routine in PyLongslit produces a wavelength solution $\Lambda(x, \lambda)$, that maps a spacial pixel coordinate $x$ and spectral pixel coordinate $\lambda$ to a wavelength. The error estimate for the mapped wavelength is simply calculated by using equation ($\ref{model_error}$):

\begin{equation}\label{wave_sol_error}
    \sigma_{\Lambda} = \text{RMS}(\tilde{\Lambda}(\tilde{x},\tilde{\lambda}) - \Lambda(\tilde{x},\tilde{\lambda})) \ \ ,
\end{equation}

\noindent where $\tilde{\Lambda}(x,\lambda)$ is the measured wavelength of identified calibration-lines at pixels $(\tilde{x},\tilde{\lambda})$. The expression "measured wavelength" is however a bit misleading, as the wavelengths are measured by manual pattern-matching and then several fitting routines to refine the calibration-lamp/sky line wavelengths and positions, and therefore the measured wavelengths $\tilde{\Lambda}$ might carry a significant error of their own. This said, the wavelength measurement algorithm can be set to be very conservative (rejecting any fits that do not comply with user defined metrics), in order to minimize this error.\\
\\
\textbf{The wavelength calibration routine is by far the most complex routine in the whole pipeline, and the above described error estimation is extremely simplified in favour of robustness. We therefore advise the user to pay great attention to the quality assessment plots to asses the quality of the modelling.}

\subsection{Master flat-field}\label{master-flat}

Firstly, a median master flat $F_{\text{master}}$ is produced with the same procedure as with the master bias. The only difference is that the master bias and the dark current (if present) are subtracted from the raw flat-field frames before median estimation. The error introduced by this subtraction is ignored in the median estimation, with the same argumentation as given in chapter (\ref{ignore_overscan}) for overscan.\\
\\
Then, the spectral response (and possibly slit illumination profile - if user chooses) are normalized using fitted models $M$: 

\begin{equation}\label{spectral_norm}
    F_{\text{master (spectral normalized)}}(x,y) = \frac{F_{\text{master (not normalized)}}(x,y)}{M_{\text{spectral}}(x,y)} \ \ ,
\end{equation}

\begin{equation}\label{spatial_norm}
    F_{\text{master}}(x,y) = 
    \begin{cases}
        \frac{F_{\text{master (spectral normalized)}}(x,y)}{M_{\text{illumination}}(x,y)}, & \text{with slit-illumination normalisation ,} \\
        F_{\text{master (spectral normalized)}}(x,y), & \text{without slit-illumination normalisation ,}
    \end{cases}
\end{equation}

\noindent For eq. (\ref{spectral_norm}), the error propagation is calculated using eq. (\ref{combination}) (omitting $(x,y)$ in notation for readability):

\begin{equation}
    \sigma_{F_{\text{master (spectral normalized)}}} = F_{\text{master (spectral normalized)}} \sqrt{\left(\frac{\sigma_{F_{\text{master (not normalized)}}}}{F_{\text{master (not normalized)}}}\right)^2 + \left(\frac{\sigma_{M_{\text{spectral}}}}{M_{\text{spectral}}}\right)^2} \ \ ,
\end{equation}

\noindent and then, if slit-illumination normalization is performed (eq. (\ref{spatial_norm})): 

\begin{equation}
    \sigma_{F_{\text{master}}} = F_{\text{master}} \sqrt{\left(\frac{\sigma_{F_{\text{master (spectral normalized)}}}}{F_{\text{master (spectral normalized)}}}\right)^2 + \left(\frac{\sigma_{M_{\text{illumination}}}}{M_{\text{illumination}}}\right)^2} \ \ ,
\end{equation}

\noindent where the errors for the spectral response model $M_{spectral}$ and slit-illumination model $M_{illumination}$ are calculated from the residuals using eq. (\ref{model_error}).

\section{Reduction of the object frames}

\subsection{Initial error estimation of raw target frames}

For raw target frames (both object and standard star), a similar approach is taken as in \cite[p. 45 - 46]{handbook} for initial error estimation. It is assumed that the raw frames primely consist of the detected light, the dark current (if any is present), and the bias detector level. Therefore, the initial estimate of the error of the object frames is as follows (using eq. (\ref{combination}) and also adding the read noise)): 

\begin{equation}
    \sigma_{initial} = \sqrt{\sigma_{Poisson}^2 + \sigma_{D}^2 + \sigma_{O}^2 + \sigma_{B}^2 + \sigma_{Read Noise}^2} \ \ ,
\end{equation}

\noindent where $D$ stands for dark current, $O$ stands for overscan and $B$ stands for bias. $\sigma_{Poisson}$ is the photon shot noise calculated as the square root of detected light\cite[p. 45]{handbook}:

\begin{equation}
    \sigma_{Poisson}(x,y) = \sqrt{C_{initial}(x,y) - D - O(x,y) - B(x,y)} \ \ ,
\end{equation}

\noindent where $C_{initial}(x,y)$ are the total counts of the raw frame. For $\sigma_{D}$, since the software supports only subtracting a constant amount of dark current from every pixel (user inputs the dark current as a scalar in electrons/second, and then it gets converted into detector counts by the software), the error $\sigma_{D}$ is calculated as \cite[p. 45]{handbook}:

\begin{equation}
    \sigma_{D} = \sqrt{D} \ \ .
\end{equation}


\noindent $\sigma_{O}$ is calculated as the error of mean of the overscan row/column depending on the detector and user input:

\begin{equation}
    \sigma_{O} = \frac{\sigma_{std}}{\sqrt{N}} \ \ , 
\end{equation}

\noindent where $N$ is the number of pixels in the row/column of the overscan strip. The bias error $\sigma_{B}$ estimation is described in chapter (\ref{master bias}). The read noise $\sigma_{ReadNoise}$ is given as a scalar by user input (as electrons, and then converted automatically by the software to detector counts).

\subsection{Error estimation of the reduced frames}

The calibrated counts $C_{calibrated}$ for the object frames are obtained by subtracting the dark current $D$, frame overscan level $O$, detector bias $B$, and then dividing by the master flat $F$ (with $D$ and/or $O$ being 0 for some instruments):

\begin{equation}
    C_{calibrated}(x,y) = \frac{C_{initial}(x,y) - D - O(x,y) - B(x,y)}{F(x,y)} \ \ .
\end{equation}

Propagating the errors using eg. (\ref{combination}): 

\begin{equation}\label{calibed_error}
    \sigma_{C_{calibrated}} = \frac{1}{F} \sqrt{\sigma_{initial}^2 + \sigma_{D}^2 + \sigma_{O}^2 + \sigma_{B}^2 +  C_{calibrated}^2 \ \sigma_{F}^2} \ \ ,
\end{equation}

\noindent where $\sigma_{initial}, \sigma_{D}, \sigma_{O}, \sigma_{B}$ are described in the previous chapter, and $\sigma_{F}$ is described in chapter (\ref{master-flat}).\\

\noindent The errors for the dark current and the detector bias get double-counted  - once when estimating the initial error of the raw science frame, and once when estimating the error of the reduced frame. This approach is taken from \cite[p. 45-47]{handbook}, and the argument for this is that since we "count" the detector counts twice, we have to account for the errors twice.

\subsection{Cosmic-ray elimination}

The user can choose to deploy the Astro-SCRAPPY\footnote{\url{https://github.com/astropy/astroscrappy?tab=readme-ov-file}} cosmic ray detection Python package \cite{cr_2, cr_1} after the frame reduction. Errors for the pixels corresponding to the detected cosmic rays are assigned a value that is the mean error of the whole error image.

\section{Sky-subtraction errors}

Sky-subtraction in the software is optional, and can be performed in several ways - by \textbf{A-B dithering background subtraction}, by \textbf{polynomial fitting} to acquire a sky-model, or both (executed in the order they are listed in). For A-B dithering background subtraction, both frames are to be reduced beforehand, so both frames A and B have an error $\sigma_{A}$ and $\sigma_{B}$ decided by eq. (\ref{calibed_error}). The error of the background subtracted image $\sigma_{sub}$ is then decided by eq. (\ref{combination}):

\begin{equation}\label{AB error}
    \sigma_{sub} = \sqrt{\sigma_{A}^2 + \sigma_{B}^2} \ \ .
\end{equation}

\noindent For polynomial sky-estimation, a polynomial background fit is performed in the spacial direction of every spectral pixel $\lambda_{pix}$. The error for the sky estimation for the spectral pixel $\sigma_{\lambda_{pix}}$ is decided as the RMS of the residuals (eq. (\ref{model_error})). The sky-model is constructed by stacking the individual fits through the spectral axis to map the whole detector. The error image of the sky-model $\sigma_{sky}$ is likewise acquired by stacking the errors for every spectral pixel $\sigma_{\lambda_{pix}}$ through the spectral axis. The model is then subtracted from the frame. If the frame has an initial error $\sigma$ (either from eq. (\ref{calibed_error}) or eq. (\ref{AB error})), then the error on the frame with the subtracted sky model $\sigma_{sub}$ is again:

\begin{equation}\label{skysub}
    \sigma_{sub} = \sqrt{\sigma^2 + \sigma_{sky}^2} \ \ .
\end{equation}



\section{Extraction errors}

\subsection{Horne optimal extraction}

The primary extraction algorithm is the Horne optimal extraction algorithm \cite{Horne_1986}. The error for the extracted spectrum at wavelength $\lambda$ in detector counts $C_{1d}$ is estimated as: 

\begin{equation}\label{horne_error}
    \sigma_{C_{1d}}(\lambda) = \sqrt{\left(\sum_{x} \frac{P(x, \lambda)^2}{\sigma_{C_{calibrated}(x,y)^2}}\right)^{-1}} \ \ ,
\end{equation}

\noindent where $x$ is a spacial pixel(s) corresponding to wavelength $\lambda$, $P(x,\lambda)$ is a Gaussian weight for the object aperture, and $\sigma_{C_{calibrated}}$ is described in eq. (\ref{calibed_error}). For details about this equation, please refer to \cite{Horne_1986}.

\subsection{Simple photometry extraction}\label{simple_eror}

Secondary extraction option is by simply performing a photometry extraction on the estimated object aperture. For this, an out-of-the-box solution is used from \verb|photutils.aperture.RectangularAperture|, with the method \verb|do_photometry|. For the details on how the error gets estimated on the simple extraction, please refer to the method documentation at \url{https://photutils.readthedocs.io/en/2.0.2/api/photutils.aperture.RectangularAperture.html#photutils.aperture.RectangularAperture.do_photometry}.

\section{Flux-calibration errors}

When flux-calibrating the extracted 1d-spectrum from detector counts, a sensitivity function needs to be obtained first. This function is obtained by fitting a model to an array of sensitivity points $S_{points}(\lambda)$. These points are obtained by diving a flux-calibrated spectrum of a standard star (that is in the wanted units) with the obtained 1d-spectrum in counts pr. second of the same star. In PyLongslit default units:

\begin{equation}
    S_{points}(\lambda) \left[\frac{erg/cm^2/\textit{Å}}{counts}\right] = \frac{\text{1d-spec flux-calibrated spectrum} \left[erg/s/cm^2/\textit{Å}\right]}{\text{1d-spec observed spectrum i counts pr. second} \left[counts/s\right]} \ \ .
\end{equation}

\noindent Fitting a model to these points gives a conversion factor $S(\lambda)$  between observed counts pr. second $C_{1d}(\lambda)/s$ to flux in physical units $Flux(\lambda)$:

\begin{equation}\label{flux}
    Flux(\lambda) =  \frac{C_{1d}(\lambda)}{\text{exposure time}} \ S(\lambda) \ \ .
\end{equation}

\noindent In the software, the fit for $S(\lambda)$ is performed in (10-base) log-space ($S_{log}(\lambda)$). This is because the observed 1d-standard star spectrum in counts will still have some artifacts such as absorption lines from the sky, and these might corrupt the fit. Fitting in logarithmic space scales these artifacts down. The error of the fit in logspace is calculated using eq. (\ref{model_error}):

\begin{equation}
    \sigma_{S_{log}} = \text{RMS}(\log{(S_{points}(\tilde{\lambda}))} - S_{log}(\tilde{\lambda})) \ \ ,
\end{equation}

\noindent where $\tilde{\lambda}$ are the wavelengths at which the sensitivity points were evaluated.\\

\noindent To convert from $S_{log}(\lambda)$ to $S(\lambda)$, the following expression is used:

\begin{equation}
    S(\lambda) = 10^{S_{log}(\lambda)} \ \ ,
\end{equation}

\noindent and using this expression with eq. (\ref{combination}) results in following error:

\begin{equation}
    \sigma_{S(\lambda)} = \lvert \ln{(10)} \ 10^{S_{log}(\lambda)} \ \sigma_{S_{log}} \rvert \ \ . 
\end{equation}

\noindent When flux calibrating a 1d-spectrum that is in counts using eq. (\ref{combination}) and eq. (\ref{flux}), and assuming the error on the exposure time is negligible, the error propagates to:

\begin{equation}\label{flux_final_error}
    \sigma_{Flux(\lambda)} = \sqrt{\left(\frac{S(\lambda)}{\text{exposure time}} \sigma_{C_{1d}}\right)^2 + \left(\frac{C_{1d}(\lambda)}{\text{exposure time}} \sigma_{S(\lambda)}\right)^2} \ \ ,
\end{equation}

\noindent where $\sigma_{C_{1d}}$ is defined in eq. (\ref{horne_error}) or in chapter (\ref{simple_eror}), depending on what extraction algorithm is chosen by the user.


\section{Spectrum-Combining errors}

PyLongslit has a routine for combination of flux-calibrated 1d-spectra. The spectra are combined as a weighted mean $Flux_{\mu}(\lambda)$, where the errors from eq. (\ref{flux_final_error}) are used as weights \cite[p. 54]{barlow1995statistics}: 

\begin{Large}
    

\begin{equation}
    Flux_{\mu}(\lambda) =  \frac{\sum_{i} \frac{Flux_{i}(lambda)}{\sigma_{i_{Flux(\lambda)}}^2}}{\sum_{i} \frac{1}{\sigma_{i_{Flux(\lambda)}}^2}} \ \ , 
\end{equation}


\end{Large}


\noindent with the error:

\begin{Large}

\begin{equation}
\sigma_{Flux_{\mu}(\lambda)} = \sqrt{\frac{1}{\sum_{i} \frac{1}{\sigma_{i_{Flux(\lambda)}}^2}}}
\end{equation}

\end{Large}



%\printbibliography[heading=none] % Print the bibliography normally
\printbibliography
\end{document}
